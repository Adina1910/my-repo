{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c5afa5-2294-41a3-b128-556473512615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number of students:  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Student 1:\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Example: Hours studied vs Marks\n",
    "# ------------------------------\n",
    "\n",
    "'''hours_studied   = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "actual_marks    = [35, 42, 48, 55, 60, 62, 70, 80, 85, 90]\n",
    "predicted_marks = [30, 45, 50, 52, 58, 65, 68, 75, 88, 92]'''\n",
    "\n",
    "hours_studied = []\n",
    "actual_marks = []\n",
    "predicted_marks = []\n",
    "\n",
    "n = int(input(\"Enter number of students: \"))\n",
    "\n",
    "for i in range(n):\n",
    "    print(f\"\\nStudent {i+1}:\")\n",
    "    h = int(input(\"  Enter hours studied: \"))\n",
    "    a = int(input(\"  Enter actual marks: \"))\n",
    "    p = int(input(\"  Enter predicted marks: \"))\n",
    "\n",
    "    hours_studied.append(h)\n",
    "    actual_marks.append(a)\n",
    "    predicted_marks.append(p)\n",
    "\n",
    "# Calculate average marks (to compare high vs low)\n",
    "mean_marks = sum(actual_marks) / len(actual_marks)\n",
    "\n",
    "# Initialize counts\n",
    "TP = TN = FP = FN = 0\n",
    "\n",
    "for actual, predicted in zip(actual_marks, predicted_marks):\n",
    "    if actual >= mean_marks and predicted >= mean_marks:\n",
    "        TP += 1   # correctly predicted high marks\n",
    "    elif actual < mean_marks and predicted < mean_marks:\n",
    "        TN += 1   # correctly predicted low marks\n",
    "    elif actual < mean_marks and predicted >= mean_marks:\n",
    "        FP += 1   # predicted high but actually low\n",
    "    elif actual >= mean_marks and predicted < mean_marks:\n",
    "        FN += 1   # predicted low but actually high\n",
    "\n",
    "# ----- Calculate metrics manually -----\n",
    "accuracy  = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "recall    = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "f1_score  = (2 * precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "# ----- Print results -----\n",
    "print(\"Hours studied  :\", hours_studied)\n",
    "print(\"Actual marks   :\", actual_marks)\n",
    "print(\"Predicted marks:\", predicted_marks)\n",
    "print(\"Mean marks     :\", round(mean_marks, 2))\n",
    "\n",
    "print(\"\\nTrue Positive (TP):\", TP)\n",
    "print(\"True Negative (TN):\", TN)\n",
    "print(\"False Positive (FP):\", FP)\n",
    "print(\"False Negative (FN):\", FN)\n",
    "\n",
    "print(\"\\nAccuracy :\", round(accuracy, 3))\n",
    "print(\"Precision:\", round(precision, 3))\n",
    "print(\"Recall   :\", round(recall, 3))\n",
    "print(\"F1 Score :\", round(f1_score, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a2fdfe-4676-44c7-a3bb-d51d591e1a63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
